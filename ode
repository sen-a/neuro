import jax.numpy as np
import jaxlib
import matplotlib.pyplot as plt
from jax import random
from jax import grad
from jax import vmap
from jax import jit
import numpy as nnp

#dy/dx = 4x^3 - 3x^2 + 2, x[0,1]
#y(0)=0
#H=15






def sigmoid(x):
    return 1./(1. + np.exp(-x))

def f(params, x):
    w0 = params[:5]
    b0 = params[5:10]
    w1 = params[10:15]
    x = sigmoid(x*w0 + b0)
    x = nnp.sum(x*w1)
    return x


nnp.random.seed(1)
params = nnp.random.randn((15))







dfdx = grad(f, 1)


inputs = np.linspace(0., 1., num=6)


f_vect = vmap(f, (None, 0))
dfdx_vect = vmap(dfdx, (None, 0))




def loss(params, inputs):
    eq = dfdx_vect(params, inputs) - 4. * inputs**3. + 3. * inputs**2. - 2.
    ic = f(params, 0.) - 0.
    return np.mean(eq**2) + ic**2



grad_loss = jit(grad(loss, 0))

epochs = 1000
learning_rate = 0.1
momentum = 0.99
velocity = 0.





for epoch in range(epochs):
    if epoch % 100 == 0:
        print('epoch: %3d loss: %.6f' % (epoch, loss(params, inputs)))
    gradient = grad_loss(params + momentum*velocity, inputs)
    velocity = momentum*velocity - learning_rate*gradient
    params += velocity


print('baslangıc ağirliklar')
print(nnp.random.randn((15)))
print('ağırlıkların son halleri')
print(params)

plt.plot(inputs, inputs**4 - inputs**3 + 2*inputs, label='exact')
plt.plot(inputs, f_vect(params, inputs), label='approx')
plt.legend()
plt.show()
